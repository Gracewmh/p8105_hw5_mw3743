---
title: "Homework 5 Iteration"
author: "Minghui Wang" 
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---
This assignment reinforces ideas in [Iteration](https://p8105.com/topic_iteration.html).

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
set.seed(123)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1
Write a function that, for a fixed group size, randomly draws ‚Äúbirthdays‚Äù for each person; checks whether there are duplicate birthdays in the group; and returns TRUE or FALSE based on the result.
```{r}
bday_sim = function(n) {

  bdays = sample(1:365, size = n, replace = TRUE)
  
  duplicate = length(unique(bdays)) < n

  return(duplicate)
}
```

Run this function 10000 times for each group size between 2 and 50. For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs.
```{r}
sim_res = 
  expand_grid(
    n = 2:50,
    iter = 1:10000
  ) |> 
  mutate(res = map_lgl(n, bday_sim)) |> 
  group_by(n) |> 
  summarize(prob = mean(res))
```
 Make a plot showing the probability as a function of group size, and comment on the results.
```{r}
sim_res |> 
  ggplot(aes(x = n, y = prob )) + 
  geom_point(alpha=0.5) +
  geom_smooth()+
  labs(
    x= "Group Size (n)",
    y= "Probability",
    title = "Probability of Duplicate Birthdays as Group Size Increases"
  )
```

**Comment** : The plot shows an increasing trend in the probability that at least two people share a birthday as the group size grows. The probability starts near zero for small groups but rises quickly, reaching around 50% by a group size of 23, and approaching nearly 100% by a group size of 50. The increasing rate is biggest around a group size of 23 and smallest around 0 and 50. This plot demonstrates how the likelihood of shared birthdays increases as more people are added.

# Problem 2
Define the function to save ùúáÃÇ and the p-value arising from a test of ùêª:ùúá=0 using ùõº=0.05.
```{r}
# Set parameters

alpha <- 0.05

# Define t_test function  
t_test = function(mu) {
  
  sample_data = rnorm(30, mean = mu, sd = 5)
  
  t_stat = t.test(sample_data, mu = 0) |>
    broom::tidy() |>
    select(estimate, p.value)
  
  return(t_stat)
}
```

```{r}
# Generate 5000 dataset for mu = 0
sim_result_mu0 = 
  tibble(
    mu = 0,
    iter = 1:5000
  ) |>
  mutate(
    estimate_df = map(mu, t_test)
  ) |> 
  unnest(estimate_df)
```

```{r}
# Simulation for each mu(1-6) value and store results
sim_result_mu1_6 =
  expand_grid(
    mu = 1:6,
    iter = 1:5000 )|>
  mutate(
    estimate_df = map(mu, t_test)
  )|> 
  unnest(estimate_df)

# Combine the two datasets
sim_result_df = bind_rows(sim_result_mu0, sim_result_mu1_6)
```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of ùúá
 on the x axis. Describe the association between effect size and power.
```{r}
sim_result_df |>
  group_by(mu) |>
  summarize(
    power = mean(p.value < alpha), .groups = 'drop')|>
  ggplot( aes(x = mu, y = power)) +
    geom_line() +
    geom_point() +
    labs(
      title = "Power of the t-Test ",
      x = "True Value of Œº",
      y = "Power (proportion of times the null was rejected)"
    ) +
    theme_minimal()
```

**Comment** : The plot demonstrates that power increases with effect size; as the true mean (ùúá) becomes larger, the probability of rejecting the null hypothesis rises.When Œº is small (close to 0), the power is low, indicating a low probability of detecting a true effect.As Œº increases, the power steadily rises, and by the time Œº reaches around 4, the power approaches 1, meaning the test is highly likely to reject the null hypothesis when it is false. This highlights the positive relationship between effect size and the test's ability to detect a true effect.<br>

Make a plot showing the average estimate of ùúáÃÇ on the y axis and the true value of ùúá on the x axis.
```{r}
sim_result_df |>
  group_by(mu) |>
  summarize(
    avg_mu = mean(estimate), .groups = 'drop')|>
  ggplot( aes(x = mu, y = avg_mu) )+
  geom_line() +
  geom_point() +
  labs(
      title = "Average Estimate of Sample Mean (ŒºÃÇ) vs True Value of Population Mean (Œº)",
      x = "True Value of Œº",
      y = "Average Estimate of ŒºÃÇ"
    ) +
    theme_minimal()
```

Make a second plot (or overlay on the first) the average estimate of ùúáÃÇ only in samples for which the null was rejected on the y axis and the true value of ùúáon the x axis. Is the sample average of ùúáÃÇ across tests for which the null is rejected approximately equal to the true value of ùúá? Why or why not?
```{r}
sim_result_df |>
  group_by(mu) |>
  summarize(
    avg_mu_hat = mean(estimate),  
    avg_mu_hat_rejected = mean(estimate[p.value < 0.05]),  
    .groups = 'drop'
  ) |>
  ggplot(aes(x = mu)) +
  geom_line(aes(y = avg_mu_hat, color = "All Samples"), linetype = "solid") +
  geom_point(aes(y = avg_mu_hat, color = "All Samples")) +
  geom_line(aes(y = avg_mu_hat_rejected, color = "Null Rejected Samples"), linetype = "solid") +
  geom_point(aes(y = avg_mu_hat_rejected, color = "Null Rejected Samples")) +
  labs(
    title = "Average Estimate of Sample Mean (ŒºÃÇ) vs True Value of Population Mean (Œº)",
    x = "True Value of Œº", y = "Average Estimate of ŒºÃÇ", color = "Sample Type" ) +
  theme_minimal()
```

**Is the sample average of ùúáÃÇ across tests for which the null is rejected approximately equal to the true value of Œº? **
The sample average of ùúáÃÇ across tests for which the null hypothesis is rejected is not approximately equal to the true value of Œº, especially for smaller values of Œº.<br>
**Why or why not?**: When we only consider samples where the null hypothesis was rejected, we introduce selection bias. This occurs because we are selectively choosing samples that show stronger evidence against the null hypothesis, which typically results in larger observed estimates. When the true effect size is small, only the samples with higher-than-average estimates of ùúáÃÇ will have a significant p-value, and thus only those are included in the "null rejected" category.However, when the true effect size is big, this bias is reduced, resulting in the estimated value close to the true value. 

# Problem 3
Load the raw dataset
```{r}
homicide_raw = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/refs/heads/master/homicide-data.csv")
```
**Describe the raw data**<br>
This dataset has 52,179 records about incidents involving victims, with 12 columns describing each case. Each record has a unique ID, the date it was reported (reported_date), and victim information such as last name (victim_last), first name (victim_first), race (victim_race), age (victim_age), and sex (victim_sex), ect. The location of the incident is listed by city, state, and geographic coordinates (latitude and longitude). The last column, disposition, shows the outcome of the case, like "Closed without arrest" or "Closed by arrest." <br>


Create a city_state variable (e.g. ‚ÄúBaltimore, MD‚Äù) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is ‚ÄúClosed without arrest‚Äù or ‚ÄúOpen/No arrest‚Äù).
```{r}
homicide_unsolved = homicide_raw |>
  mutate(
    city_state = str_c(city, ",", state)) |>
  group_by(city_state)|>
  summarize(
    total_homicides = n(),
    total_unsolved = sum(disposition == "Closed without arrest" | disposition == "Open/No arrest")
  )
```


For the city of Baltimore, MD, use the `prop.test` function to estimate the proportion of homicides that are unsolved; save the output of `prop.test` as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.
```{r}
baltimore = homicide_unsolved|>
  filter(city_state == "Baltimore,MD")


baltimore_prop_test =  prop.test(
  x = baltimore$total_unsolved,
  n = baltimore$total_homicides
)

broom::tidy(baltimore_prop_test) |>
  select(estimate, conf.low, conf.high)|>  
  knitr::kable()
  
```
Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a ‚Äútidy‚Äù pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.
```{r}
cities_prop_test = homicide_unsolved|>
  mutate(
    prop_test_result = map2(
      total_unsolved,
      total_homicides,
      ~ prop.test (x=.x,n=.y)),
    tidy_result = map (prop_test_result, broom::tidy)
  )|>
  select(city_state, tidy_result) |>
  unnest()|>
  select(city_state, estimate, conf.low, conf.high)

cities_prop_test |>
  knitr::kable()
```


Create a plot that shows the estimates and CIs for each city ‚Äì check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

```{r}
cities_prop_test |>
  mutate(
    city_state = reorder(city_state, estimate)
  )|>
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip()+
  labs(
    title = "Proportion of Unsolved Homicides by City, State",
    x = "City, State",
    y = "Proportion of Unsolved Homicides",
    caption = "Error bars represent 95% CI"
  ) +
  theme_minimal(base_size = 6) 
```



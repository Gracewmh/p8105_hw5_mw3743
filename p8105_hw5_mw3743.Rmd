---
title: "Homework 5 Iteration"
author: "Minghui Wang" 
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---
This assignment reinforces ideas in [Iteration](https://p8105.com/topic_iteration.html).

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
set.seed(123)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1
Write a function that, for a fixed group size, randomly draws ‚Äúbirthdays‚Äù for each person; checks whether there are duplicate birthdays in the group; and returns TRUE or FALSE based on the result.
```{r}
bday_sim = function(n) {

  bdays = sample(1:365, size = n, replace = TRUE)
  
  duplicate = length(unique(bdays)) < n

  return(duplicate)
}
```

Run this function 10000 times for each group size between 2 and 50. For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs.
```{r}
sim_res = 
  expand_grid(
    n = 2:50,
    iter = 1:10000
  ) |> 
  mutate(res = map_lgl(n, bday_sim)) |> 
  group_by(n) |> 
  summarize(prob = mean(res))
```
 Make a plot showing the probability as a function of group size, and comment on the results.
```{r}
sim_res |> 
  ggplot(aes(x = n, y = prob )) + 
  geom_point(alpha=0.5) +
  geom_smooth()+
  labs(
    x= "Group Size (n)",
    y= "Probability",
    title = "Probability of Duplicate Birthdays as Group Size Increases"
  )
```

**Comment** : The plot shows an increasing trend in the probability that at least two people share a birthday as the group size grows. The probability starts near zero for small groups but rises quickly, reaching around 50% by a group size of 23, and approaching nearly 100% by a group size of 50. The increasing rate is biggest around a group size of 23 and smallest around 0 and 50. This plot demonstrates how the likelihood of shared birthdays increases as more people are added.

# Problem 2
Define the function to save ùúáÃÇ and the p-value arising from a test of ùêª:ùúá=0 using ùõº=0.05.
```{r}
# Set parameters

alpha <- 0.05

# Define t_test function  
t_test = function(mu) {
  
  sample_data = rnorm(30, mean = mu, sd = 5)
  
  t_stat = t.test(sample_data, mu = 0) |>
    broom::tidy() |>
    select(estimate, p.value)
  
  return(t_stat)
}
```

```{r}
# Generate 5000 dataset for mu = 0
sim_result_mu0 = 
  tibble(
    mu = 0,
    iter = 1:5000
  ) |>
  mutate(
    estimate_df = map(mu, t_test)
  ) |> 
  unnest(estimate_df)
```

```{r}
# Simulation for each mu(1-6) value and store results
sim_result_mu1_6 =
  expand_grid(
    mu = 1:6,
    iter = 1:5000 )|>
  mutate(
    estimate_df = map(mu, t_test)
  )|> 
  unnest(estimate_df)

# Combine the two datasets
sim_result_df = bind_rows(sim_result_mu0, sim_result_mu1_6)
```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of ùúá
 on the x axis. Describe the association between effect size and power.
```{r}
sim_result_df |>
  group_by(mu) |>
  summarize(
    power = mean(p.value < alpha), .groups = 'drop')|>
  ggplot( aes(x = mu, y = power)) +
    geom_line() +
    geom_point() +
    labs(
      title = "Power of the t-Test ",
      x = "True Value of Œº",
      y = "Power (proportion of times the null was rejected)"
    ) +
    theme_minimal()
```

**Comment** : The plot demonstrates that power increases with effect size; as the true mean (ùúá) becomes larger, the probability of rejecting the null hypothesis rises.When Œº is small (close to 0), the power is low, indicating a low probability of detecting a true effect.As Œº increases, the power steadily rises, and by the time Œº reaches around 4, the power approaches 1, meaning the test is highly likely to reject the null hypothesis when it is false. This highlights the positive relationship between effect size and the test's ability to detect a true effect.


Make a plot showing the average estimate of ùúáÃÇ on the y axis and the true value of ùúá on the x axis.
```{r}
sim_result_df |>
  group_by(mu) |>
  summarize(
    avg_mu = mean(estimate), .groups = 'drop')|>
  ggplot( aes(x = mu, y = avg_mu) )+
  geom_line() +
  geom_point() +
  labs(
      title = "Average Estimate of Sample Mean (ŒºÃÇ) vs True Value of Population Mean (Œº)",
      x = "True Value of Œº",
      y = "Average Estimate of ŒºÃÇ"
    ) +
    theme_minimal()
```
 Make a second plot (or overlay on the first) the average estimate of ùúáÃÇ only in samples for which the null was rejected on the y axis and the true value of ùúáon the x axis. Is the sample average of ùúáÃÇ across tests for which the null is rejected approximately equal to the true value of ùúá? Why or why not?
```{r}
sim_result_df |>
  group_by(mu) |>
  summarize(
    avg_mu_hat = mean(estimate),  
    avg_mu_hat_rejected = mean(estimate[p.value < 0.05]),  
    .groups = 'drop'
  ) |>
  ggplot(aes(x = mu)) +
  geom_line(aes(y = avg_mu_hat, color = "All Samples"), linetype = "solid") +
  geom_point(aes(y = avg_mu_hat, color = "All Samples")) +
  geom_line(aes(y = avg_mu_hat_rejected, color = "Null Rejected Samples"), linetype = "solid") +
  geom_point(aes(y = avg_mu_hat_rejected, color = "Null Rejected Samples")) +
  labs(
    title = "Average Estimate of Sample Mean (ŒºÃÇ) vs True Value of Population Mean (Œº)",
    x = "True Value of Œº", y = "Average Estimate of ŒºÃÇ", color = "Sample Type" ) +
  theme_minimal()
```

**Is the sample average of ùúáÃÇ across tests for which the null is rejected approximately equal to the true value of Œº? **
The sample average of ùúáÃÇ across tests for which the null hypothesis is rejected is not approximately equal to the true value of Œº, especially for smaller values of Œº.
**Why or why not?**: When we only consider samples where the null hypothesis was rejected, we introduce selection bias. This occurs because we are selectively choosing samples that show stronger evidence against the null hypothesis, which typically results in larger observed estimates. When the true effect size is small, only the samples with higher-than-average estimates of ùúáÃÇ will have a significant p-value, and thus only those are included in the "null rejected" category.However, when the true effect size is big, this bias is reduced, resulting in the estimated value close to the true value. 

# Problem 3
```{r}
```